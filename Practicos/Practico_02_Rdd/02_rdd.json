{"paragraphs":[{"text":"val baseDir=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/practicos/02_rdd\"\nprint(\"\"\"%html\n<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti  </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n\"\"\")\n","dateUpdated":"2017-09-27T00:51:09-0300","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<center>\n    <h1>Programación Distribuida sobre Grandes Volúmenes de Datos</h1>\n</center>\n\n<br>\n\n<h3 style=\"text-align:center;\">\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    Facultad de Matemática Astronomía Física y Computación\n    </a>\n<br/>\n    <a href=\"http://www.unc.edu.ar\">\n    Universidad Nacional de Córdoba\n    </a>\n<br/>\n    <center>\n    <a href=\"http://www.famaf.unc.edu.ar\">\n    <img src=\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/comun/logo%20UNC%20FAMAF%202016.svg\" alt=\"Drawing\" style=\"width:50%;\"/>\n    </a>\n    </center>\n</h3>\n\n<h4 style=\"text-align:center;\"> Damián Barsotti  </h4>\n\n<p style=\"font-size:15px;\">\n    <br />\n        This work is licensed under a\n        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n        <img alt=\"Creative Commons License\" style=\"border-width:0;vertical-align:middle;float:right\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" />\n    </a>\n</p>\n"}]},"apps":[],"jobName":"paragraph_1506484269167_975912295","id":"20160720-155403_1624436783","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26"},{"text":"%md\n# Práctico 2\n\n## RDD\n\n**Nota**: Todos los ejercicios deben hacerse utilizando la api Spark/Scala de RDD's.","dateUpdated":"2017-09-27T00:51:09-0300","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Práctico 2</h1>\n<h2>RDD</h2>\n<p><strong>Nota</strong>: Todos los ejercicios deben hacerse utilizando la api Spark/Scala de RDD's.</p>\n"}]},"apps":[],"jobName":"paragraph_1506484269168_986300515","id":"20160720-160358_1849828329","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:27"},{"text":"%md\n### Ejercicio ~\n\nEn la presentación de rdd se mostró un programa que filtra las apariciones de las palabras \"config\" y \"status\":\n```\nval inputRDD = sc.textFile(\"/doc/log.txt\") // RDD\nval statusRDD = inputRDD.filter(line => line.contains(\"ERROR\")) // se crea un nuevo RDD\nval configRDD = inputRDD.filter(line => line.contains(\"config\")) // se crea un nuevo RDD\nval stOrConfRDD = statusRDD.union(configRDD) \n```\nEsta solución puede ser poco eficiente ya que el archivo se recorre dos veces.\nHacer un programa que recorra el archivo solo una vez filtrando ambas apariciones al mismo tiempo.\nComprobar la mejora viendo el grafo en la SparkUI.\n","dateUpdated":"2017-09-27T00:51:09-0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>En la presentación de rdd se mostró un programa que filtra las apariciones de las palabras &ldquo;config&rdquo; y &ldquo;status&rdquo;:</p>\n<pre><code>val inputRDD = sc.textFile(&quot;/doc/log.txt&quot;) // RDD\nval statusRDD = inputRDD.filter(line =&gt; line.contains(&quot;ERROR&quot;)) // se crea un nuevo RDD\nval configRDD = inputRDD.filter(line =&gt; line.contains(&quot;config&quot;)) // se crea un nuevo RDD\nval stOrConfRDD = statusRDD.union(configRDD) \n</code></pre>\n<p>Esta solución puede ser poco eficiente ya que el archivo se recorre dos veces.<br/>Hacer un programa que recorra el archivo solo una vez filtrando ambas apariciones al mismo tiempo.<br/>Comprobar la mejora viendo el grafo en la SparkUI.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269169_985915766","id":"20160720-160508_1035497333","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:28"},{"text":"val inputRDD = sc.textFile(\"./doc/log.txt\") // RDD\nval stOrConfRDD = inputRDD.filter(line => line.contains(\"ERROR\") || line.contains(\"config\")) // se crea un nuevo RDD\nstOrConfRDD.take(10).foreach(println)","user":"anonymous","dateUpdated":"2017-09-27T01:13:00-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = ./doc/log.txt MapPartitionsRDD[186] at textFile at <console>:30\n\nstOrConfRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[187] at filter at <console>:32\n[     5.422] Markers: (--) probed, (**) from config file, (==) default setting,\n\t(WARN) warning, (ERROR) error, (NI) not implemented, (??) unknown.\n[     5.423] (==) Using system config directory \"/usr/share/X11/xorg.conf.d\"\n\tUsing a default monitor configuration.\n\tIf no devices become available, reconfigure udev or disable AutoAddDevices.\n[     5.426] (==) Matched intel as autoconfigured driver 0\n[     5.426] (==) Matched vesa as autoconfigured driver 1\n[     5.426] (==) Matched fbdev as autoconfigured driver 2\n[     5.812] (INFO) config/udev: Adding input device Power Button (/dev/input/event2)\n[     5.813] (**) Option \"config_info\" \"udev:/sys/devices/LNXSYSTM:00/LNXPWRBN:00/input/input2/event2\"\n"}]},"apps":[],"jobName":"paragraph_1506484269171_986685264","id":"20170915-184231_1265885495","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:13:00-0300","dateFinished":"2017-09-27T01:13:05-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:29"},{"text":"%md\n### Ejercicio ~\n\nHacer un programa que cuente las palabras del archivo `README.md`.\n","dateUpdated":"2017-09-27T00:51:09-0300","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>Hacer un programa que cuente las palabras del archivo <code>README.md</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269172_984761520","id":"20160720-173000_305100573","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30"},{"text":"val inputRDD = sc.textFile(\"./README.md\") // RDD\nval stOrConfRDD = inputRDD.flatMap(line => line.split(\" \")) // se crea un nuevo RDD\nstOrConfRDD.count()\n","user":"anonymous","dateUpdated":"2017-09-27T01:28:23-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = ./README.md MapPartitionsRDD[192] at textFile at <console>:30\n\nstOrConfRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[193] at flatMap at <console>:32\n\nres94: Long = 123\n"}]},"apps":[],"jobName":"paragraph_1506484269173_984376771","id":"20170915-185144_1668987445","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:28:24-0300","dateFinished":"2017-09-27T01:28:40-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31"},{"text":"%md\n### Ejercicio ~\n\nImplementar la acción `count` solo con la acción `aggregate`. Hacer algunas pruebas con el programa.    \n","dateUpdated":"2017-09-27T00:51:09-0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>Implementar la acción <code>count</code> solo con la acción <code>aggregate</code>. Hacer algunas pruebas con el programa.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269174_985531017","id":"20160713-190552_1151608518","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:32"},{"text":"val input = sc.parallelize(1 to 30)\nval result = input.aggregate(0)(\n                             (acc, value) => (acc + 1),\n                             (acc1, acc2) => (acc1 + acc2))\n\n","user":"anonymous","dateUpdated":"2017-09-27T01:28:48-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninput: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[194] at parallelize at <console>:30\n\nresult: Int = 30\n"}]},"apps":[],"jobName":"paragraph_1506484269175_985146269","id":"20170915-185716_2023028893","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:28:48-0300","dateFinished":"2017-09-27T01:28:50-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:33"},{"text":"%md\n### Ejercicio ~\nContar la cantidad de veces que aparece la letra 'c' en el archivo `README.md`.","dateUpdated":"2017-09-27T00:51:09-0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>Contar la cantidad de veces que aparece la letra &lsquo;c&rsquo; en el archivo <code>README.md</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269176_983222524","id":"20160721-171403_50576689","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:34"},{"text":"val inputRDD = sc.textFile(\"/home/mario/Documentos/FaMAF/Optativas/BigData_2017/zeppelin-0.7.2-bin-all/README.md\") // RDD\nval stOrConfRDD = inputRDD.flatMap(line => line.split(\"\")).filter(letra => letra == \"c\") // se crea un nuevo RDD\nstOrConfRDD.count()\n","user":"anonymous","dateUpdated":"2017-09-27T01:33:00-0300","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = /home/mario/Documentos/FaMAF/Optativas/BigData_2017/zeppelin-0.7.2-bin-all/README.md MapPartitionsRDD[204] at textFile at <console>:30\n\nstOrConfRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[206] at filter at <console>:32\n\nres97: Long = 42\n"}]},"apps":[],"jobName":"paragraph_1506484269177_982837775","id":"20170915-190422_541442815","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:32:28-0300","dateFinished":"2017-09-27T01:32:31-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:35"},{"text":"%md\n### Ejercicio ~\n\nDevolver todos los links internos del archivo `wikipedia_short.xml` (el archivo esta en el la página de la materia o en el directorio `/doc`).\nPueden aparecer varios links en una lines y son de la forma `[[link]]` o `[[link|text]]`.\n**Ayuda**: ver [información sobre expresiones regulares en Scala](https://www.safaribooksonline.com/library/view/scala-cookbook/9781449340292/ch01s07.html).","dateUpdated":"2017-09-27T00:51:09-0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>Devolver todos los links internos del archivo <code>wikipedia_short.xml</code> (el archivo esta en el la página de la materia o en el directorio <code>/doc</code>).<br/>Pueden aparecer varios links en una lines y son de la forma <code>[[link]]</code> o <code>[[link|text]]</code>.<br/><strong>Ayuda</strong>: ver <a href=\"https://www.safaribooksonline.com/library/view/scala-cookbook/9781449340292/ch01s07.html\">información sobre expresiones regulares en Scala</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269178_983992022","id":"20160721-210216_414292177","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:36"},{"text":"val inputRDD = sc.textFile(\"/home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml\") // RDD\nval Pattern = raw\"\\[\\[([^\\]]+)\\]\\]\".r\nval stOrConfRDD = inputRDD.flatMap(Pattern.findAllIn(_).toList).map(x => x.slice(2,x.length()-2).split('|')(0)) // se crea un nuevo RDD\nstOrConfRDD.take(30).foreach(println)\n","user":"anonymous","dateUpdated":"2017-09-27T01:34:30-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = /home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml MapPartitionsRDD[208] at textFile at <console>:30\n\nPattern: scala.util.matching.Regex = \\[\\[([^\\]]+)\\]\\]\n\nstOrConfRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[210] at map at <console>:34\nWP:RCAT\nComputer accessibility\npolitical philosophy\nself-governance\nstateless society\nHierarchy\nFree association (communism and anarchism)\nPeter Kropotkin\nAn Anarchist FAQ\nstate (polity)\nThe Globe and Mail\nRoutledge Encyclopedia of Philosophy\nanti-statism\nauthority\nhierarchical organisation\nInternational of Anarchist Federations\nMurray Bookchin\nEmma Goldman\nAnarchism and Other Essays\nBenjamin Tucker\nGeorge Woodcock\nMikhail Bakunin\nAnarchist schools of thought\nindividualism\nsocial anarchism\nindividualist anarchism\nGeoffrey Ostergaard\nleft-wing\nThe New York Times\nanarchist economics\n"}]},"apps":[],"jobName":"paragraph_1506484269179_983607273","id":"20170915-190928_630131156","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:34:30-0300","dateFinished":"2017-09-27T01:34:32-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:37"},{"text":"%md\n### Ejercicio ~\n\nDado el archivo `wikipedia_short.xml` contar las cantidad de lineas que tienen la palabra \"human\", las que tienen la palabra \"activity\" y las que tienen ambas palabras utilizando `intersection` (puede suponer que no hay lineas repetidas).\nProbar hacer el programa sin y con persistencia en memoria y comparar los resultados utilizando *Spark UI*.","dateUpdated":"2017-09-27T00:51:09-0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ejercicio ~</h3>\n<p>Dado el archivo <code>wikipedia_short.xml</code> contar las cantidad de lineas que tienen la palabra &ldquo;human&rdquo;, las que tienen la palabra &ldquo;activity&rdquo; y las que tienen ambas palabras utilizando <code>intersection</code> (puede suponer que no hay lineas repetidas).<br/>Probar hacer el programa sin y con persistencia en memoria y comparar los resultados utilizando <em>Spark UI</em>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1506484269180_981683528","id":"20160721-215626_699372770","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38"},{"text":"val inputRDD = sc.textFile(\"/home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml\") // RDD\n\nval RDD1 = inputRDD.filter(line => line.contains(\"human\")) // se crea un nuevo RDD\nval RDD2 = inputRDD.filter(line => line.contains(\"activity\")) // se crea un nuevo RDD\nval RDDI = RDD1.intersection(RDD2)\nRDD1.count()\nRDD2.count()\nRDDI.count()\n","user":"anonymous","dateUpdated":"2017-09-27T01:34:50-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = /home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml MapPartitionsRDD[212] at textFile at <console>:30\n\nRDD1: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[213] at filter at <console>:33\n\nRDD2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[214] at filter at <console>:32\n\nRDDI: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[220] at intersection at <console>:36\n\nres100: Long = 15\n\nres101: Long = 12\n\nres102: Long = 5\n"}]},"apps":[],"jobName":"paragraph_1506484269181_981298780","id":"20170916-204209_805659754","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:34:50-0300","dateFinished":"2017-09-27T01:34:53-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:39"},{"text":"val inputRDD = sc.textFile(\"/home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml\") // RDD\n\nval RDD1 = inputRDD.filter(line => line.contains(\"human\")).cache() // se crea un nuevo RDD\nval RDD2 = inputRDD.filter(line => line.contains(\"activity\")).cache() // se crea un nuevo RDD\nval RDDI = RDD1.intersection(RDD2).cache()\nRDD1.count()\nRDD2.count()\nRDDI.count()\n","user":"anonymous","dateUpdated":"2017-09-27T01:34:58-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ninputRDD: org.apache.spark.rdd.RDD[String] = /home/mario/Documentos/FaMAF/Optativas/BigData_2017/Practicos/Practico_02_Rdd/wikipedia_short.xml MapPartitionsRDD[222] at textFile at <console>:30\n\nRDD1: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[223] at filter at <console>:33\n\nRDD2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[224] at filter at <console>:32\n\nRDDI: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[230] at intersection at <console>:36\n\nres104: Long = 15\n\nres105: Long = 12\n\nres106: Long = 5\n"}]},"apps":[],"jobName":"paragraph_1506484269182_982453026","id":"20170916-205157_1830457953","dateCreated":"2017-09-27T00:51:09-0300","dateStarted":"2017-09-27T01:34:58-0300","dateFinished":"2017-09-27T01:35:00-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:40"},{"title":"FIN","text":"println(\"\"\"%html\n<script>\n    var heads = document.getElementsByTagName('h3');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 0;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.search(\"Ejercicio\") != -1 ) {\n            j++;\n            heads[i].innerHTML = inner.replace(/Ejercicio (~|\\d+)/,\"Ejercicio \"+j);\n        }\n        i++\n    }\n</script>\n\"\"\")","dateUpdated":"2017-09-27T00:51:09-0300","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<script>\n    var heads = document.getElementsByTagName('h3');\n    var numHeads = heads.length;\n    var inner = \"\";\n    var i = 0;\n    var j = 0;\n    while (i < numHeads){\n        inner = heads[i].innerHTML;\n        if (inner.search(\"Ejercicio\") != -1 ) {\n            j++;\n            heads[i].innerHTML = inner.replace(/Ejercicio (~|\\d+)/,\"Ejercicio \"+j);\n        }\n        i++\n    }\n</script>\n\n"}]},"apps":[],"jobName":"paragraph_1506484269183_982068277","id":"20160720-160531_894116655","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:41"},{"dateUpdated":"2017-09-27T00:51:09-0300","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1506484269184_1066328286","id":"20160801-161002_153562124","dateCreated":"2017-09-27T00:51:09-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42"}],"name":"Práctico 2 - RDD","id":"2CWGEWHFQ","angularObjects":{"2CQY683MD:shared_process":[],"2CRGPDJTN:shared_process":[],"2CTZD3XCX:shared_process":[],"2CRMCDEQM:shared_process":[],"2CTAV9E28:shared_process":[],"2CRA7KCDA:shared_process":[],"2CQ81X7G5:shared_process":[],"2CRUQ6EVN:shared_process":[],"2CTHYC7X9:shared_process":[],"2CRHWDFYM:shared_process":[],"2CQJ7MXW5:shared_process":[],"2CQAR5VSM:shared_process":[],"2CRCFF6HB:shared_process":[],"2CTK8TR8Q:shared_process":[],"2CQN5Q87B:shared_process":[],"2CTW5YZGW:shared_process":[],"2CSR7EJVT:shared_process":[],"2CRUQ7EXT:shared_process":[],"2CRFFBRXJ:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}